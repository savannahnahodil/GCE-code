# calibration_script.py lines 1-491
"""
Â© (or copyright) 2023. Triad National Security, LLC. All rights reserved.
This program was produced under U.S. Government contract 89233218CNA000001 for Los Alamos
National Laboratory (LANL), which is operated by Triad National Security, LLC for the U.S.
Department of Energy/National Nuclear Security Administration. All rights in the program are
reserved by Triad National Security, LLC, and the U.S. Department of Energy/National Nuclear
Security Administration. The Government is granted for itself and others acting on its behalf a
nonexclusive, paid-up, irrevocable worldwide license in this material to reproduce, prepare
derivative works, distribute copies to the public, perform publicly and display publicly, and to permit
others to do so.

This program is open source under the BSD-3 License.
Redistribution and use in source and binary forms, with or without modification, are permitted
provided that the following conditions are met:
1. Redistributions of source code must retain the above copyright notice, this list of conditions and
the following disclaimer.

2.Redistributions in binary form must reproduce the above copyright notice, this list of conditions
and the following disclaimer in the documentation and/or other materials provided with the
distribution.

3.Neither the name of the copyright holder nor the names of its contributors may be used to endorse
or promote products derived from this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS
IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR
CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;
OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR
OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
"""

import numpy as np
import copy
from random import random

from JINAPyCEE import omega_plus

def linear_interp(array, time_array, time):
    '''
    Interpolate array at time "time"
    '''

    err_msg = f"Interpolation time {time:.2e}"
    err_msg2 = "than time_array"

    # Time greater than time_arr[-1]
    if time_array[-1] < time:
        s = err_msg + " greater " + err_msg2
        s += f"[-1], {time_array[-1]:.2e}"
        raise Exception(s)

    # Time lower than time_arr[0]
    if time_array[0] > time:
        s = err_msg + " lower " + err_msg2
        s += f"[0], {time_array[0]:.2e}"
        raise Exception(s)

    # Search for the time
    for ii in range(len(array)):
        if time_array[ii] >= time:
            time1 = time_array[ii - 1]
            time2 = time_array[ii]

            val1 = array[ii - 1]
            val2 = array[ii]

            # Interpolate linearly
            val = (time - time1)*(val2 - val1)/(time2 - time1) + val1
            return val

def run_omega(kwargs, param_vals, param_norms, time=8.4e9):
    '''Run omega with all the parameters'''

    # Recover parameters
    kwargs_alt = {}
    for key in param_vals:
        if key not in ["a1", "b1", "imf_yield_top"]:
            kwargs[key] = param_vals[key] * param_norms[key]
        else:
            kwargs_alt[key] = param_vals[key] * param_norms[key]

    # Define the inflow rates
    # [norm, t_max, timescale]
    exp_infall = [[kwargs_alt["a1"], 0.0, 0.68e9],
                  [kwargs_alt["b1"], 1.0e9, 7.0e9]] # this is good
    kwargs["exp_infall"] = exp_infall
    kwargs["imf_yields_range"] = [1, kwargs_alt["imf_yield_top"]]

    # Running omega
    op = omega_plus.omega_plus(**kwargs)

    # Extract values
    time_arr = op.inner.history.age
    sfr = op.inner.history.sfr_abs[-1]
    inflow_rate = op.inner.m_inflow_t[-1]/op.inner.history.timesteps[-1]
    m_gas = np.sum(op.inner.ymgal[-1])
    cc_sne_rate = op.inner.sn2_numbers[-1]/op.inner.history.timesteps[-1]
    Ia_sne_rate = op.inner.sn1a_numbers[-1]/op.inner.history.timesteps[-1]

    # Get the metallicity (mass fraction)
    metallicity = np.zeros(op.inner.nb_timesteps + 1)
    for i_t in range(op.inner.nb_timesteps + 1):
        m_Z = 0.0
        for iso, y in zip(op.inner.history.isotopes, op.inner.ymgal[i_t]):
            if iso.split("-")[0] not in ["H", "He", "Li"]:
                m_Z += y
        metallicity[i_t] = m_Z / np.sum(op.inner.ymgal[i_t])

    metallicity = linear_interp(metallicity, time_arr, time=time)

    # Get stellar mass
    m_star_lost = np.sum(np.sum(op.inner.mdot))
    stellar_mass = np.sum(op.inner.history.m_locked) - m_star_lost

    # Get abundances at time of sun formation
    masses = linear_interp(op.inner.ymgal, time_arr, time=time)
    m_tot = np.sum(masses)

    # Grab the iron
    name = "Fe"
    indices = [ii for ii, x in enumerate(op.inner.history.isotopes)
                    if x.split("-")[0] == name]
    FeMass = np.sum(masses[indices])
    XFe = FeMass/m_tot

    # Store values and return
    values = {}
    values["sfr"] = sfr
    values["stellar_mass"] = stellar_mass
    values["inflow_rate"] = inflow_rate
    values["m_gas"] = m_gas
    values["cc_sne_rate"] = cc_sne_rate
    values["Ia_sne_rate"] = Ia_sne_rate
    values["XFe"] = XFe
    values["metallicity"] = metallicity

    return op, values

def copy_yields(kwargs, op):
    '''
    Copy the yields from the op simulation to the kwargs dictionary
    '''

    kwargs_yields = copy.deepcopy(kwargs)

    kwargs_yields["input_yields"] = True
    kwargs_yields["isotopes_in"] = op.inner.history.isotopes
    kwargs_yields["ytables_in"] = op.inner.ytables
    kwargs_yields["ytables_1a_in"] = op.inner.ytables_1a
    kwargs_yields["ytables_nsmerger_in"] = op.inner.ytables_nsmerger
    kwargs_yields["inter_Z_points"] = op.inner.inter_Z_points
    kwargs_yields["nb_inter_Z_points"] = op.inner.nb_inter_Z_points
    kwargs_yields["y_coef_M"] = op.inner.y_coef_M
    kwargs_yields["y_coef_M_ej"] = op.inner.y_coef_M_ej
    kwargs_yields["y_coef_Z_aM"] = op.inner.y_coef_Z_aM
    kwargs_yields["y_coef_Z_bM"] = op.inner.y_coef_Z_bM
    kwargs_yields["y_coef_Z_bM_ej"] = op.inner.y_coef_Z_bM_ej
    kwargs_yields["tau_coef_M"] = op.inner.tau_coef_M
    kwargs_yields["tau_coef_M_inv"] = op.inner.tau_coef_M_inv
    kwargs_yields["tau_coef_Z_aM"] = op.inner.tau_coef_Z_aM
    kwargs_yields["tau_coef_Z_bM"] = op.inner.tau_coef_Z_bM
    kwargs_yields["tau_coef_Z_aM_inv"] = op.inner.tau_coef_Z_aM_inv
    kwargs_yields["tau_coef_Z_bM_inv"] = op.inner.tau_coef_Z_bM_inv
    kwargs_yields["y_coef_M_pop3"] = op.inner.y_coef_M_pop3
    kwargs_yields["y_coef_M_ej_pop3"] = op.inner.y_coef_M_ej_pop3
    kwargs_yields["tau_coef_M_pop3"] = op.inner.tau_coef_M_pop3
    kwargs_yields["tau_coef_M_pop3_inv"] = op.inner.tau_coef_M_pop3_inv
    kwargs_yields["inter_lifetime_points_pop3"] = op.inner.inter_lifetime_points_pop3
    kwargs_yields["inter_lifetime_points_pop3_tree"] = op.inner.inter_lifetime_points_pop3_tree
    kwargs_yields["nb_inter_lifetime_points_pop3"] = op.inner.nb_inter_lifetime_points_pop3
    kwargs_yields["inter_lifetime_points"] = op.inner.inter_lifetime_points
    kwargs_yields["inter_lifetime_points_tree"] = op.inner.inter_lifetime_points_tree
    kwargs_yields["nb_inter_lifetime_points"] = op.inner.nb_inter_lifetime_points
    kwargs_yields["nb_inter_M_points_pop3"] = op.inner.nb_inter_M_points_pop3
    #kwargs_yields["inter_M_points_pop3"] = op.inner.inter_M_points_pop3
    #kwargs_yields["inter_M_points_pop3_tree"] = op.inner.inter_M_points_pop3_tree
    kwargs_yields["nb_inter_M_points"] = op.inner.nb_inter_M_points
    kwargs_yields["inter_M_points"] = op.inner.inter_M_points
    #kwargs_yields["inter_M_points_tree"] = op.inner.inter_M_points_tree
    kwargs_yields["y_coef_Z_aM_ej"] = op.inner.y_coef_Z_aM_ej

    return kwargs_yields

def run_calibration(kwargs, kwargs_yields, weights, values, param_vals,\
        param_norms, sol_ranges, fix_params, threshold=2e-2,\
        lf=1e0, momentum=0.5, max_iter=10, time=8.4e9, max_lf_f=2,
        min_lf_f=1, period_lf=20):

    '''
    Calibrate omega using gradient descent
    '''

    # Save the learning factor
    lf0 = lf

    # Get the target solutions and deltas_deriv
    solutions = {}; deltas_deriv = {}
    for key in sol_ranges:
        solutions[key] = np.mean(sol_ranges[key])
    for key in param_vals:
        deltas_deriv[key] = lf * 1e-1

    best_solution = None
    best_parameters = None
    smallest_error = None
    prev_changes = {key: None for key in param_vals}

    # Perform gradient descent
    ii = 0
    while True:
        try:
            # Print current solution
            print("----------")
            print("Current solution")
            for key, val in values.items():
                sol = solutions[key]
                print(f"{key}: {val:.2e} - {sol:.2e}")

            print()
            print("Current parameters")
            for key in param_vals:
                val = param_vals[key]*param_norms[key]
                print(f"{key}: {val:.2e}")

            # Check the solution to see if it's good enough
            rel_error = {}
            sum_err = 0; sum_weights = 0
            for key in values:
                rel_error[key] = (values[key] - solutions[key])
                rel_error[key] *= weights[key]/solutions[key]

                sum_err += rel_error[key]**2
                sum_weights += weights[key]**2

            error = sum_err/sum_weights
            if smallest_error is None or error < smallest_error:
                smallest_error = error
                best_solution = copy.copy(values)
                best_parameters = copy.copy(param_vals)

            print()
            print(f"Current error = {error:.4f}; threshold = {threshold:.4f}")
            print()
            if error < threshold:
                print("----------")
                print()
                print("Error threshold achieved")
                break

            # Open derivatives file
            deriv_file = "derivatives.txt"
            fwrite = open(deriv_file, "w")

            # If it is not good enough, calculate the derivatives
            param_cpy = copy.copy(param_vals)
            norm_gradient = 0
            derivs = {}
            for key in param_vals:
                derivs[key] = 0

                # If this parameter is fixed, do not change it
                if fix_params[key]:
                    continue

                print(f"Derivating parameter {key}")

                # Change only one parameter
                param_cpy[key] += deltas_deriv[key]
                if key == "imf_yield_top":
                    op, new_values = run_omega(kwargs, param_cpy,\
                                               param_norms, time=time)
                else:
                    op, new_values = run_omega(kwargs_yields, param_cpy,\
                                               param_norms, time=time)

                # Calculate derivative
                # This array holds the derivative of all the values (sfr, inflow...)
                # with respect to the ii-th parameter (a1, b1, imf_yield_top, sfe...)
                for key2 in values:
                    # Do parametric derivative
                    der = (new_values[key2] - values[key2])/deltas_deriv[key]

                    # Save
                    val = der/param_norms[key]
                    s = f"Derivative of {key2} with {key} = {val:.2e}\n"
                    fwrite.write(s)

                    # Continue with relative error derivative
                    der *= rel_error[key2]*weights[key2]/solutions[key2]
                    derivs[key] += der
                derivs[key] *= 2
                norm_gradient += derivs[key]**2

                # Restore the previous value
                param_cpy[key] = param_vals[key]
                fwrite.write("=========\n")

            # Close derivatives file
            fwrite.close()

            # And multiply by factors
            changes = {}
            for key in derivs:
                changes[key] = derivs[key] * lf
                if prev_changes[key] is not None:
                    changes[key] *= (1 - momentum)

            # Re-calculate deltas
            for key in deltas_deriv:
                deltas_deriv[key] = abs(changes[key]) * lf * 1e-1
                deltas_deriv[key] = max(deltas_deriv[key],
                        abs(1e-1 * lf * param_vals[key]))

            # Now calculate the new parameters and do the new run
            print("Calculating next solution")
            for key in derivs:
                # calculate change with momentum
                if prev_changes[key] is not None:
                    changes[key] += momentum * prev_changes[key]

                # Apply change
                param_vals[key] -= changes[key]

            # Store change
            prev_changes = changes

            # Run omega with the new parameters
            op, values = run_omega(kwargs, param_vals, param_norms)
            kwargs_yields = copy_yields(kwargs, op)

            # Change learning factor with the period given by the user
            if ii%period_lf < period_lf/2:
                lf = 2*(max_lf_f - min_lf_f)/period_lf*(ii%period_lf) + min_lf_f
            else:
                lf = 2*(min_lf_f - max_lf_f)/period_lf*(ii%period_lf - period_lf/2) + max_lf_f
            lf *= lf0

            ii += 1
            if (ii > max_iter):
                print("----------")
                print()
                print("Maximum of iterations reached")
                break

        except KeyboardInterrupt:
            break
        except:
            raise

    # Print best solution
    with open("output.txt", "w") as fwrite:
        print()
        print("----------")
        s = f"Best solution with error: {smallest_error:.4f}"
        print(s)
        fwrite.write(s + "\n")

        values = best_solution
        for key, val in values.items():
            s = f"{key} = {val:.2e}"

            print(s)
            fwrite.write(s + "\n")

        print()
        s = "Best parameters"
        print(s)
        fwrite.write("\n" + s + "\n")

        param_vals = best_parameters
        param_vals["t_sun"] = time
        param_norms["t_sun"] = 1
        for key in param_vals:
            val = param_vals[key]*param_norms[key]
            s = f"{key} = {val:.2e}"

            print(s)
            fwrite.write(s + "\n")

        print()
        print(f"Iterations: {ii}")

# Parameters for the machine-learning

# Maximum relative error
threshold = 5e-4 # Maximum relative error

# Maximum parameter step when error = 1
learning_factor = 1e-4

# Momentum of the descent
momentum = 0.90

# Maximum iterations before the program exits
max_iter = 10

# Define omega arguments
#table = 'yield_tables/AK_stable.txt'
#table = 'yield_tables/agb_and_massive_stars_nugrid_MESAonly_fryer12delay.txt'
table = 'yield_tables/agb_and_massive_stars_K10_K06_0.5HNe.txt'

# Immutable
kwargs = {}
kwargs["Z_trans"] = -1
kwargs["t_star"] = 1.0
kwargs["table"] = table
kwargs["mgal"] = 1.0
kwargs["m_DM_0"] = 1.0e12
kwargs["sn1a_rate"] = 'power_law'
kwargs["print_off"] = True

kwargs["special_timesteps"] = 300
#kwargs["dt"] = 5e8

# Weight dictionary
weights = {}
weights["sfr"] = 1
weights["stellar_mass"] = 1
weights["inflow_rate"] = 1
weights["m_gas"] = 1
weights["cc_sne_rate"] = 1
weights["Ia_sne_rate"] = 1
weights["XFe"] = 1
weights["metallicity"] = 4

# Define ranges of solutions. The solution must fall inside these ranges
sol_ranges = {}
sol_ranges["sfr"] = [2.5, 3.5]
sol_ranges["stellar_mass"] = [3.0e10, 4.0e10]
sol_ranges["inflow_rate"] = [0.1, 1.1]
sol_ranges["m_gas"] = [1.21e10, 1.31e10]
sol_ranges["cc_sne_rate"] = [2.5e-2, 3.5e-2]
sol_ranges["Ia_sne_rate"] = [5e-3, 7e-3]
sol_ranges["XFe"] = [1.28e-3, 1.32e-3]
sol_ranges["metallicity"] = [0.0152, 0.0154]

# Define ranges of parameters. These give an idea to the code on the scale
# of the changes it should expect, but they are not hard limits.
param_ranges = {}
param_ranges["a1"] = [0, 150]
param_ranges["b1"] = [0, 15]
param_ranges["imf_yield_top"] = [20, 50]
param_ranges["sfe"] = [1e-10, 1e-9]
param_ranges["mass_loading"] = [0, 2]
param_ranges["nb_1a_per_m"] = [5e-4, 2e-3]

# Initial values (guess for parameter values)
param_vals = {}
param_vals["a1"] = 52.3
param_vals["b1"] = 3.47
param_vals["imf_yield_top"] = 36.0
param_vals["sfe"] = 1.65e-10
param_vals["mass_loading"] = 0.170
param_vals["nb_1a_per_m"] = 1.59e-3

# Whether to fix a parameter so it does not change
fix_params = {}
fix_params["a1"] = False
fix_params["b1"] = False
fix_params["imf_yield_top"] = False
fix_params["sfe"] = False
fix_params["mass_loading"] = False
fix_params["nb_1a_per_m"] = False

# -------------- Do not change anything below this line -------------------

# Define array of parameters
param_norms = {}
for key in param_ranges:
    lst = param_ranges[key]
    param_norms[key] = lst[1] - lst[0]
    param_vals[key] /= param_norms[key]

# Run initial omega
op, values = run_omega(kwargs, param_vals, param_norms)

# Before continuing, copy the yield tables
kwargs_yields = copy_yields(kwargs, op)

# Now calibrate:
time = 8.4e9
run_calibration(kwargs, kwargs_yields, weights, values, param_vals,\
        param_norms, sol_ranges, fix_params, threshold=threshold,\
        lf=learning_factor, momentum=momentum, max_iter=max_iter, time=time,\
        max_lf_f=2, min_lf_f=0.5, period_lf=20)




#convert_tree.py lines 496-697

"""
Author: Alex Ji
31 Jul 2018
"""
import numpy as np
import haloutils
import time, sys, os

OUTPUTDIR="/blender/data/alexji/gamma_trees"
assert os.path.exists(OUTPUTDIR)

"""
Merger Tree Columns
tree.data.dtype.names
['scale', 'id', 'desc_id', 'num_prog', 'pid', 'upid', 'phantom',
'sam_mvir', 'mvir', 'rvir', 'rs', 'vrms', 'mmp', 'scale_of_last_MM',
'vmax', 'posX', 'posY', 'posZ', 'pecVX', 'pecVY', 'pecVZ', 'Jx',
'Jy', 'Jz', 'spin', 'bfid', 'dfid', 'origid', 'lastprog_dfid',
'm200c_all', 'm200b', 'xoff', 'voff', 'spin_bullock',
'b_to_a(500c)', 'c_to_a(500c)', 'A[x](500c)', 'A[y](500c)',
'A[z](500c)', 'T/|U|', 'snap']
"""

h0 = 0.6711

def fill_branch_info(br_halo_ID, br_age, br_z, br_m_halo,
                     br_r_vir, hid, iz, iz_cur, times, redshifts, node_cur,
                     br_is_sub):

    """
    Fill the halo ID, age, and mass of the current halo in a branch.
    """

    # Copy the halo ID
    br_halo_ID[iz][-1].append(hid)

    # Calculate the age of the branch
    br_age[iz][-1].append(times[iz_cur] - times[iz])

    # Calculate the redshift of the branch
    br_z[iz][-1].append(redshifts[iz_cur])

    # Copy the halo mass of the current halo
    #br_m_halo[iz][-1].append(float(node_cur['Mvir'].in_units('Msun')))
    br_m_halo[iz][-1].append(float(node_cur['mvir']/h0))

    # Copy the virial radius
    br_r_vir[iz][-1].append(float(node_cur['rvir']/h0 /\
        (1.0 + redshifts[iz_cur])))

    # Copy subhalo status
    br_is_sub[iz][-1].append(node_cur["upid"]!=-1)

def convert_tree(hpath, tree, treeoutputpath, verbose=True):
    # Maps to go up and down trees
    # desc_map is analogous to merger_tree_ytree.add_descendants()
    # mmp = "most massive progenitor" flag
    start = time.time()
    desc_map = tree.get_desc_map()
    if verbose: print "  Time to precompute tree maps: {:.1f}".format(time.time()-start); sys.stdout.flush()
    num_nodes_in_tree = len(tree.data)
    num_nodes_processed = 0

    ## This gets the scale factors etc for Caterpillar
    snaps = np.unique(tree["snap"])
    times = haloutils.get_t_snap(hpath,snaps)*1e9 #Gyr
    redshifts = haloutils.get_z_snap(hpath,snaps)
    ## Convert some things to lists for list.index() method
    snaps = list(snaps)

    # NOTE: a branch is a multi-snapshot segment of the tree that experiences no mergers
    # Declare the arrays
    br_halo_ID  = []  # List of connected halo IDs (in redshift order)
    br_age      = []  # Age of the branch
    br_z        = []  # Redshift of the branch
    br_t_merge  = []  # Duration of the branches (delay between formation and merger)
    br_ID_merge = []  # Last halo ID of the branch (once it has merged)
    br_m_halo   = []  # Array of dark matter halo masses
    br_r_vir    = []  # Array of dark matter halo radii
    br_is_sub   = []  # Array of True if the halo is a subhalo, False if is a host halo
    br_is_prim  = []  # True or False depending whether the branch is primordial

    # Create an entry for each redshift
    for i_z in range(0,len(redshifts)):
        br_halo_ID.append([])
        br_age.append([])
        br_z.append([])
        br_t_merge.append([])
        br_ID_merge.append([])
        br_m_halo.append([])
        br_r_vir.append([])
        br_is_sub.append([])
        br_is_prim.append([])

    start = time.time()
    ## Loop through all nodes of the tree that are branch points
    for irow,row in enumerate(tree.data):
        i_z = snaps.index(row["snap"])
        ## If exactly one progenitor, this is not a branching point, so skip it
        if row["num_prog"] == 1: continue
        # Create a new branch for the considered redshift
        br_halo_ID[i_z].append([])
        br_age[i_z].append([])
        br_z[i_z].append([])
        br_t_merge[i_z].append(0.0)
        br_ID_merge[i_z].append(0.0)
        br_m_halo[i_z].append([])
        br_r_vir[i_z].append([])
        br_is_sub[i_z].append([])

        ## Assign whether or not this is a primordial branch
        br_is_prim[i_z].append(row["num_prog"] == 0)

        ## Fill the start of the branch
        ## Fill the halo ID, age, mass, and radius
        # Note: the ID is the mtid!!! not sure if this is what we actually want
        # To access that object in the halo catalogs, we need origid and snapshot
        fill_branch_info(br_halo_ID, br_age, br_z, br_m_halo, br_r_vir,
                         row["id"], i_z, i_z, times, redshifts, row, br_is_sub)
        num_nodes_processed += 1
        ## Step down the tree
        desc_irow = tree.getDesc(irow, desc_map)
        if desc_irow is None: continue # reached the root
        desc_row = tree[desc_irow]
        ## Loop through subsequent parts of the branch, defined as single-progenitor
        while desc_row["num_prog"] == 1:
            ## Fill next part of the branch
            i_z_cur = snaps.index(desc_row["snap"])
            fill_branch_info(br_halo_ID, br_age, br_z, br_m_halo, br_r_vir,
                             desc_row["id"], i_z, i_z_cur, times, redshifts, desc_row, br_is_sub)
            num_nodes_processed += 1
            ## Step down the tree
            desc_irow = tree.getDesc(desc_irow, desc_map)
            if desc_irow is None: break # reached the root
            desc_row = tree[desc_irow]

        # Calculate the time before merger
        i_z_last = snaps.index(desc_row["snap"])
        br_t_merge[i_z][-1] = times[i_z_last] - times[i_z]
        # Copy the last halo ID (when the branch has merged)
        br_ID_merge[i_z][-1] = desc_row["id"]
    if verbose: print "  Time to convert: {:.1f}".format(time.time()-start); sys.stdout.flush()
    if num_nodes_processed != num_nodes_in_tree:
        raise ValueError("ERROR! num nodes processed != num nodes in tree ({} != {})".format(num_nodes_processed, num_nodes_in_tree))

    start = time.time()
    np.save(treeoutputpath,[br_halo_ID, br_age, br_z, br_t_merge, br_ID_merge, \
                            br_m_halo, br_r_vir, br_is_prim, redshifts, times, tree[0]['id'], br_is_sub])
    if verbose:
        print "  Time to save: {:.1f}".format(time.time()-start); sys.stdout.flush()
        print

def convert_all_trees(hid, lx, Mpeakmin):
    print "Converting all halos for H{} LX{}, Mpeakmin={:.1e}".format(hid,lx,Mpeakmin)
    halodir = os.path.join(OUTPUTDIR,"{}_LX{}".format(haloutils.hidstr(hid),lx))
    print "Outputting to",halodir
    if not os.path.exists(halodir):
        print halodir,"does not exist, creating"
        os.makedirs(halodir)

    start = time.time()
    hpath = haloutils.get_hpath_lx(hid, lx)
    zoomid = haloutils.load_zoomid(hpath)
    # This contains a dictionary of Trees, keyed by RSID at z=0
    arbor = haloutils.load_zoom_mtc(hpath, indexbyrsid=True)
    print "Time to load catalog: {:.1f}".format(time.time()-start); sys.stdout.flush()
    print

    num_trees_tried = 0
    num_trees_written = 0
    startall = time.time()
    for itree, tree in arbor.Trees.iteritems():
        treeoutputpath = os.path.join(halodir,"rsid{}.npy".format(itree))
        num_trees_tried += 1
        ## TODO use Kaley's better Mpeaks
        mb = tree.getMainBranch()
        Mpeak = np.max(mb["mvir"]/h0)
        if Mpeak < Mpeakmin: continue
        print "  Converting tree {} Mpeak={:.1e} to {}".format(itree, Mpeak, treeoutputpath)
        try:
            convert_tree(hpath, tree, treeoutputpath)
            num_trees_written += 1
        except Exception as e:
            print "ERROR!!!"
            print e
            print "Skipping this tree"
            print
    print "DONE! Processed {}/{} trees, Total time = {:.1f}".format(num_trees_written, num_trees_tried, time.time()-startall)

if __name__=="__main__":
    hids = [1725272, 1387186, 5320]
    lxs = [11]#, 12, 13, 14]
    #lxs = [11, 12]
    #hids = [1725272]
    #hids = [1387186,5320]
    #lxs = [13,14]
    Mpeakmin = 1e8
    for lx in lxs:
        for hid in hids:
            convert_all_trees(hid, lx, Mpeakmin)






#gamma.py lines 700-1320
from __future__ import (division, print_function, absolute_import,
                        unicode_literals)

'''

GAMMA (Galaxy Assembly with Merger trees for Modeling Abundances)

 - May2017: B. Cote

Definitions

    Halo : One "halo" at a specific redshift
    Primordial halo : Halo that formed naturally, not from a merger
    Branch : Evolution of dark matter without merger (series of halos)
    Merger : Merger of two or more branches

    A branch typically contains many halos, since the "same" halo has
    different identification for each redshift.. even if no merger occured.

Each branch is represented by an OMEGA_SAM or OMEGA simulation:

    OMEGA (One-zone Model for the Evolution of GAlaxies) module

    OMEGA_SAM is a 2-zone models with OMEGA at the center surrounded by halo gas

'''

# Standard packages
import numpy as np
import time as t_module
import os
import multiprocessing as mp
import copy

# Define where is the working directory
# This is where the NuPyCEE code will be extracted
nupy_path = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))
nupy_path = os.path.join(nupy_path, "NuPyCEE")

# Import NuPyCEE and JINAPyCEE codes
import NuPyCEE.read_yields as ry
import NuPyCEE.omega as omega
import JINAPyCEE.omega_plus as omega_plus


#####################
# Class Declaration #
#####################

class gamma():

    # Initialisation function
    def __init__(self, tree_trunk_ID=-1, mvir_sf_tresh=-1, n_proc = 1, \
                 table='yield_tables/agb_and_massive_stars_nugrid_MESAonly_fryer12delay.txt', \
                 pop3_table='yield_tables/popIII_heger10.txt', \
                 br_r_vir=[], redshifts=[], times=[], br_halo_ID=[], br_age=[], \
                 br_z=[], br_t_merge=[], br_ID_merge=[], br_m_halo=[], \
                 br_is_prim=[], br_is_SF=[], br_sfe_t=[], br_sfh=[], \
                 br_is_sub=[], br_is_SF_t=[], sne_L_feedback=[], **kwargs):

        # Check if we have the trunk ID
        if tree_trunk_ID < 0:
            print ('Error - GAMMA needs the tree_trunk_ID parameter.')
            return

        # Announce the beginning of the simulation
        print ('GAMMA run in progress..')
        start_time = t_module.time()
        self.start_time = start_time

        # Keep the OMEGA parameters in memory
        self.kwargs = kwargs
        self.kwargs["table"] = table
        self.kwargs["pop3_table"] = pop3_table
        self.kwargs["sne_L_feedback"] = sne_L_feedback

        # Keep the GAMMA parameters in memory
        self.kwargs = kwargs
        self.tree_trunk_id = tree_trunk_ID
        self.redshifts = redshifts
        self.times = times
        self.br_halo_ID = br_halo_ID
        self.br_age = br_age
        self.br_z = br_z
        self.br_t_merge = br_t_merge
        self.br_ID_merge = br_ID_merge
        self.br_m_halo = br_m_halo
        self.br_is_prim = br_is_prim
        self.br_is_SF = br_is_SF
        self.br_is_SF_t = br_is_SF_t
        self.br_sfe_t = br_sfe_t
        self.br_sfh = br_sfh
        self.len_br_is_SF = len(br_is_SF)
        self.len_br_sfe_t = len(br_sfe_t)
        self.len_br_is_SF_t = len(br_is_SF_t)
        self.len_br_sfh = len(br_sfh)
        self.br_r_vir = br_r_vir
        self.br_is_sub = br_is_sub
        self.mvir_sf_tresh = mvir_sf_tresh
        self.n_proc = n_proc
        self.sne_L_feedback = sne_L_feedback
        self.len_sne_L_feedback = len(sne_L_feedback)

        # Return if inputs not ok
        if self.len_br_is_SF_t > 0 and self.len_br_is_SF == 0:
            print ('Error - br_is_SF_t cannot be used without br_is_SF.')
            return

        # Initialisation of the parameters
        self.__initialisation()

        # Run the simulation
        self.__start_simulation()

        # Announce the end of the simulation
        print ('   GAMMA run completed -',self.__get_time())

    ##############################################
    #                  Get Time                  #
    ##############################################
    def __get_time(self):

        out = 'Run time: ' + \
        str(round((t_module.time() - self.start_time),2))+"s"
        return out


    ##############################################
    #               Initialisation               #
    ##############################################
    def __initialisation(self):

        '''
        Read the merger tree and declare and fill arrays.

        '''

        # Run an OMEGA simulation in order to copy basic arrays
        self.o_ini = omega.omega(table=self.kwargs["table"], \
                                 pop3_table=self.kwargs["pop3_table"],\
                                 special_timesteps=2, cte_sfr=0.0, \
                                 mgal=1e10, print_off=True)

        # Add NuPyCEE kwargs arguments to speed-up the initialization of branches
        self.kwargs["input_yields"] = True
        self.kwargs["ytables_in"] = self.o_ini.ytables
        self.kwargs["isotopes_in"] = self.o_ini.history.isotopes
        self.kwargs["ytables_1a_in"] = self.o_ini.ytables_1a
        self.kwargs["inter_Z_points"] = self.o_ini.inter_Z_points
        self.kwargs["nb_inter_Z_points"] = self.o_ini.nb_inter_Z_points
        self.kwargs["y_coef_M"] = self.o_ini.y_coef_M
        self.kwargs["y_coef_M_ej"] = self.o_ini.y_coef_M_ej
        self.kwargs["y_coef_Z_aM"] = self.o_ini.y_coef_Z_aM
        self.kwargs["y_coef_Z_bM"] = self.o_ini.y_coef_Z_bM
        self.kwargs["y_coef_Z_bM_ej"] = self.o_ini.y_coef_Z_bM_ej
        self.kwargs["tau_coef_M"] = self.o_ini.tau_coef_M
        self.kwargs["tau_coef_M_inv"] = self.o_ini.tau_coef_M_inv
        self.kwargs["tau_coef_Z_aM"] = self.o_ini.tau_coef_Z_aM
        self.kwargs["tau_coef_Z_bM"] = self.o_ini.tau_coef_Z_bM
        self.kwargs["tau_coef_Z_aM_inv"] = self.o_ini.tau_coef_Z_aM_inv
        self.kwargs["tau_coef_Z_bM_inv"] = self.o_ini.tau_coef_Z_bM_inv
        self.kwargs["y_coef_M_pop3"] = self.o_ini.y_coef_M_pop3
        self.kwargs["y_coef_M_ej_pop3"] = self.o_ini.y_coef_M_ej_pop3
        self.kwargs["tau_coef_M_pop3"] = self.o_ini.tau_coef_M_pop3
        self.kwargs["tau_coef_M_pop3_inv"] = self.o_ini.tau_coef_M_pop3_inv
        self.kwargs["inter_lifetime_points_pop3"] = self.o_ini.inter_lifetime_points_pop3
        self.kwargs["inter_lifetime_points_pop3_tree"] = self.o_ini.inter_lifetime_points_pop3_tree
        self.kwargs["nb_inter_lifetime_points_pop3"] = self.o_ini.nb_inter_lifetime_points_pop3
        self.kwargs["inter_lifetime_points"] = self.o_ini.inter_lifetime_points
        self.kwargs["inter_lifetime_points_tree"] = self.o_ini.inter_lifetime_points_tree
        self.kwargs["nb_inter_lifetime_points"] = self.o_ini.nb_inter_lifetime_points
        self.kwargs["nb_inter_M_points_pop3"] = self.o_ini.nb_inter_M_points_pop3
        self.kwargs["inter_M_points_pop3_tree"] = self.o_ini.inter_M_points_pop3_tree
        self.kwargs["nb_inter_M_points"] = self.o_ini.nb_inter_M_points
        self.kwargs["inter_M_points"] = self.o_ini.inter_M_points
        self.kwargs["y_coef_Z_aM_ej"] = self.o_ini.y_coef_Z_aM_ej

        # Calculate the number of redshifts
        self.nb_redshifts = len(self.redshifts)

        # Declare the galaxy instance array
        self.galaxy_inst = [0]*self.nb_redshifts
        for i_i in range(0,self.nb_redshifts):
           self.galaxy_inst[i_i] = [0]*len(self.br_m_halo[i_i])

        # Declare the extra initial baryonic mass added to galaxies
        self.dm_bar_added_iso = [0.0]*self.nb_redshifts
        for i_i in range(0,self.nb_redshifts):
           self.dm_bar_added_iso[i_i] = np.zeros(\
               (len(self.br_m_halo[i_i]), self.o_ini.nb_isotopes))

        # Set the final redshift
        self.kwargs["redshift_f"] = min(self.redshifts)

        # Get the primordial composition (mass fraction)
        iniabu_table = 'yield_tables/iniabu/iniab_bb_walker91.txt'
        ytables_bb = ry.read_yields_Z( \
            os.path.join(nupy_path, iniabu_table), self.o_ini.history.isotopes)
        self.prim_x_frac = np.array(ytables_bb.get(Z=0.0, quantity='Yields'))
        del ytables_bb

        # Define the information of whether branches are sub-halo or not
        if len(self.br_is_sub) > 0:
            self.is_sub_info = True
        else:
            self.is_sub_info = False


    ##############################################
    #              Start Simulation              #
    ##############################################
    def __start_simulation(self):

        '''
        Run all galaxy instance on each of the tree branch.

        '''

        # Define multiprocessing queue
        if self.n_proc > 1:
            queue = mp.Queue()

        # For each redshift ...
        for i_z_ss in range(0,self.nb_redshifts):

            # Check if each branch is primordial or not and save tuples
            branches = []; tot_branch = len(self.br_m_halo[i_z_ss])
            for i_br_ss in range(tot_branch):

                # If it's a primordial branch ...
                if self.br_is_prim[i_z_ss][i_br_ss]:
                    arguments = (self, i_z_ss, i_br_ss)

                # If the branch is the results of a merger ...
                else:

                    # Get the stellar ejecta and the ISM of all parents
                    mdot, mdot_t, ism, outer, dm, dmo, dmo_t = \
                        self.__get_mdot_parents(i_z_ss, i_br_ss)

                    arguments = (self, i_z_ss, i_br_ss, dm, mdot, mdot_t, \
                            ism, outer, dmo, dmo_t)

                # Create the Omega_Branch instance
                branches.append(Omega_Branch(arguments))

            # Now compute each galaxy
            if self.n_proc == 1 or tot_branch == 1:

                # Avoid the overhead if only one case or one process
                for i_br_ss in range(tot_branch):
                    galaxy = branches[i_br_ss].get_galaxy()
                    self.galaxy_inst[i_z_ss][galaxy[0]] = galaxy[1]

            else:

                # Divide the processes in chunks of n_proc
                i_br_ss = 0
                while i_br_ss < tot_branch:

                    # Calculate how many processes to use
                    use_proc = min(self.n_proc, tot_branch - i_br_ss)

                    # Define and run the processes
                    for ii in range(use_proc):
                        process = mp.Process(\
                            target = lambda q, o: o.get_galaxy(q), \
                            args = (queue, branches[i_br_ss + ii]))
                        process.start()

                    # Now get values
                    for ii in range(use_proc):
                        galaxy = queue.get()
                        self.galaxy_inst[i_z_ss][galaxy[0]] = galaxy[1]

                    # Increase i_br_ss
                    i_br_ss += use_proc


    ##############################################
    #              Get Mdot Parents              #
    ##############################################
    def __get_mdot_parents(self, i_z_ss, i_br_ss):

        '''
        Create an array of the mass ejected by stars as a function of
        time for all the parent branches that merge to yeild the current
        branch.  Combine the ISM of all parents.  Combine the delayed
        outflowing mass becaused of SNe feedback

        Arguments
        =========

          i_z_ss : Redshift index
          i_br_ss : Branch index

        '''

        # Find the indexes of all the parents
        i_z_par, i_br_par = self.__find_parents(i_z_ss, i_br_ss)
        nb_parents = len(i_z_par)

        # Declare the mdot arrays to be returned
        mdot = [0]*nb_parents
        mdot_t = [0]*nb_parents
        if self.len_sne_L_feedback > 0:
            dmo = [0]*nb_parents
            dmo_t = [0]*nb_parents
        ism = np.zeros(self.o_ini.nb_isotopes)
        outer = np.zeros(self.o_ini.nb_isotopes)
        dm = 0.0

        # For every parent ...
        for i_gmp in range(0,nb_parents):

            # Copy the indexes
            iz = i_z_par[i_gmp]
            ibr = i_br_par[i_gmp]

            # Add the dark matter halo mass
            dm += self.galaxy_inst[iz][ibr].inner.m_DM_t[\
               self.galaxy_inst[iz][ibr].inner.i_t_merger+1]

            # Create the parent mdot array (and delayed mass outflow if needed)
            array_len = self.galaxy_inst[iz][ibr].inner.nb_timesteps - \
                        (self.galaxy_inst[iz][ibr].inner.i_t_merger+1)
            mdot[i_gmp] = [0]*array_len
            mdot_t[i_gmp] = [0.0]*(array_len+1)
            if self.len_sne_L_feedback > 0:
                dmo[i_gmp] = [0]*array_len
                dmo_t[i_gmp] = [0.0]*(array_len+1)

            # Add time zero
            mdot_t[i_gmp][0] = 0.0
            if self.len_sne_L_feedback > 0:
                dmo_t[i_gmp][0] = 0.0

            # Combine the inner gas
            ism += self.galaxy_inst[iz][ibr].inner.ymgal[\
               self.galaxy_inst[iz][ibr].inner.i_t_merger+1]

            # Combine the outer gas
            outer += self.galaxy_inst[iz][ibr].ymgal_outer[\
               self.galaxy_inst[iz][ibr].inner.i_t_merger+1]

            # For every step starting from the merging point ...
            for i_step_om in range(0,array_len):

                # Timestep for the inner region
                i_inn = i_step_om + self.galaxy_inst[iz][ibr].inner.i_t_merger+1

                # Add the mdot value (including all isotopes)
                mdot[i_gmp][i_step_om] = self.galaxy_inst[iz][ibr].inner.mdot[i_inn]
                if self.len_sne_L_feedback > 0:
                    dmo[i_gmp][i_step_om] = \
                        self.galaxy_inst[iz][ibr].delayed_m_outflow[i_inn]

                # Add the current time since the merging point.
                # This represents the upper time limit of the current step
                mdot_t[i_gmp][i_step_om+1] = mdot_t[i_gmp][i_step_om] + \
                    self.galaxy_inst[iz][ibr].inner.history.timesteps[i_inn]
                if self.len_sne_L_feedback > 0:
                    dmo_t[i_gmp][i_step_om+1] = dmo_t[i_gmp][i_step_om] + \
                        self.galaxy_inst[iz][ibr].inner.history.timesteps[i_inn]

        # Return the stellar ejecta and the associated time
        if self.len_sne_L_feedback > 0:
            return mdot, mdot_t, ism, outer, dm, dmo, dmo_t
        else:
            return mdot, mdot_t, ism, outer, dm, np.array([]), np.array([])


    ##############################################
    #                Find Parents                #
    ##############################################
    def __find_parents(self, i_z_ss, i_br_ss):

        '''
        Find the i_z and i_br indexes of all parents of the current branch

        Arguments
        =========

          i_z_ss : Redshift index
          i_br_ss : Branch index

        '''

        # Declare the index arrays to be returned
        i_z_par = []
        i_br_par = []

        # For each previous redshift ...
        for i_z_fp in range(0,i_z_ss):

          # For each branch formed in that redshift ...
          for i_br_fp in range(0,len(self.br_ID_merge[i_z_fp])):

            # If the branch is one of the parents ...
            if self.br_ID_merge[i_z_fp][i_br_fp] == \
               self.br_halo_ID[i_z_ss][i_br_ss][0]:

                # Add the indexes in the array
                i_z_par.append(i_z_fp)
                i_br_par.append(i_br_fp)

        # Return the indexes
        return i_z_par, i_br_par


#####################
# Class Declaration #
#####################

class Omega_Branch():
    '''
    This class handles the creation of a branch for the merger tree.

    '''

    def __init__(self, args):
        '''
        This initialization class will simply create a copy of gammas' arguments.

        '''

        # Copy all gamma values
        self.__dict__ = copy.copy(args[0].__dict__)
        self.arguments = args[1:]


    ##############################################
    #                  Get galaxy                #
    ##############################################
    def get_galaxy(self, queue = None):
        '''
        Wrapper class for create_branch, it allows to call
        the class from outside without modifying it.

        '''

        gal = self.__create_branch(*self.arguments)
        if queue is not None:
            queue.put(gal)
        else:
            return gal


    ##############################################
    #               Create Branch                #
    ##############################################
    def __create_branch(self, i_z_ss, i_br_ss, dm=-1, mdot_ini=np.array([]), \
                        mdot_ini_t=np.array([]), ism_ini=np.array([]), \
                        ymgal_outer_ini=np.array([]), dmo_ini=np.array([]), \
                        dmo_ini_t=np.array([])):

        '''
        Create OMEGA to represent a specific branch from a merger tree, until
        the branch merges.

        Arguments
        =========

          i_z_ss: Redshift index
          i_br_ss: Branch index
          dm: Combined dark matter mass of the progenitors
          mdot_ini: Future stellar ejecta of the merged stellar populations
          mdot_ini_t: Times associated with the future ejecta
          ism_ini: Mass and composition of the merged inner gas reservoir
          ymgal_outer_ini: Mass and composition of the merged outer gas reservoir
          dmo_ini: Future outflow ejecta of the merged SNe (feedback)
          dmo_ini_t: Times associated with the future outflow ejecta

        '''

        # Assign the combined SSP, ISM gas, outflow (needs to be in create_omega)
        self.kwargs["mdot_ini"] = mdot_ini
        self.kwargs["mdot_ini_t"] = mdot_ini_t
        self.kwargs["ism_ini"] = ism_ini
        self.kwargs["ymgal_outer_ini"] = ymgal_outer_ini
        self.kwargs["dmo_ini"] = dmo_ini
        self.kwargs["dmo_ini_t"] = dmo_ini_t

        # Calculate the duration of the OMEGA instance
        self.kwargs["tend"] = self.times[-1] - self.times[i_z_ss] + \
                   (self.times[-1] - self.times[-2]) # Extra step for the trunk

        # Assign the DM array
        DM_array = []
        for i_cb in range(0,len(self.br_age[i_z_ss][i_br_ss])):
            DM_array.append([0.0]*2)
            DM_array[i_cb][0] = self.br_age[i_z_ss][i_br_ss][i_cb]
            DM_array[i_cb][1] = self.br_m_halo[i_z_ss][i_br_ss][i_cb]
        self.kwargs["DM_array"] = np.array(DM_array)

        # Assign the R_vir array
        r_vir_array = []
        for i_cb in range(0,len(self.br_age[i_z_ss][i_br_ss])):
            r_vir_array.append([0.0]*2)
            r_vir_array[i_cb][0] = self.br_age[i_z_ss][i_br_ss][i_cb]
            r_vir_array[i_cb][1] = self.br_r_vir[i_z_ss][i_br_ss][i_cb]
        self.kwargs["r_vir_array"] = np.array(r_vir_array)

        # Assign whether or not the branch will be a sub-halo at some point
        is_sub_array = np.array([])
        if self.is_sub_info:
            for i_cb in range(0,len(self.br_is_sub[i_z_ss][i_br_ss])):
                is_sub_array.append([0.0]*2)
                is_sub_array[i_cb][0] = self.br_age[i_z_ss][i_br_ss][i_cb]
                is_sub_array[i_cb][1] = self.br_is_sub[i_z_ss][i_br_ss][i_cb]
        self.kwargs["is_sub_array"] = is_sub_array

        # Add mass depending on the dark matter mass ratio.
        # This is because the sum of dark matter masses from the progenitors
        # sometime does not equal the initial dark matter mass of the new branch..
        if dm > 0.0:
            self.__correct_initial_state(i_z_ss, i_br_ss, \
                dm, self.br_m_halo[i_z_ss][i_br_ss][0])

        # Create a galaxy instance with external_control = True
        return self.__create_galaxy(i_z_ss, i_br_ss)


    ##############################################
    #            Correct Initial State           #
    ##############################################
    def __correct_initial_state(self, i_z_ss, i_br_ss, dm_comb, dm_ini):

        '''
        Add primordial gas if their is more dark matter than
        the sum of all pregenitors' dark matter mass. Gas is
        removed if less dark matter.

        Arguments
        =========

          i_z_ss: Redshift index
          i_br_ss: Branch index
          dm_comb : Combined dark matter mass
          dm_ini  : Initial dark matter mass according to the merger tree

        '''

        # Calculate the extra dark matter added (or removed if negative)
        dm_added = dm_ini - dm_comb

        # If we need to add primordial gas ..
        if dm_added > 0.0:

            # Calculate the baryonic mass added
            dm_bar_added = dm_added * self.o_ini.omega_b_0 / self.o_ini.omega_0
            self.dm_bar_added_iso[i_z_ss][i_br_ss] = self.prim_x_frac * dm_bar_added

            # Add or remove the mass to the halo
            self.kwargs["ymgal_outer_ini"] += self.dm_bar_added_iso[i_z_ss][i_br_ss]

        # If we need to remove gas ..
        else:

            # Calculate the fraction of halo mass that needs to stay
            f_keep_temp = dm_ini / dm_comb

            # Make sure not to remove more than available
            if f_keep_temp < 0.0:
                if np.sum(self.kwargs["ymgal_outer_ini"]) < abs(dm_added):
                    print ('Warning - Not enough outer gas for removal.', f_keep_temp)
                    f_keep_temp = 0.0

            # Correct the gas halo mass
            self.kwargs["ymgal_outer_ini"] *= f_keep_temp


    ##############################################
    #               Create Galaxy                #
    ##############################################
    def __create_galaxy(self, i_z_ss, i_br_ss):

        '''
        Create an OMEGA or OMEGA_SAM instance.

        Arguments
        =========

          i_z_ss : Redshift index
          i_br_ss : Branch index

        '''

        # Define whether the branch will form stars
        if self.len_br_is_SF > 0:
            br_is_SF_temp = self.br_is_SF[i_z_ss][i_br_ss]
        else:
            if self.kwargs["DM_array"][-1][1] >= self.mvir_sf_tresh:
                br_is_SF_temp = True
            else:
                br_is_SF_temp = False

        # Assigned pre-defined star formation timescale
        # and efficiency .. if provided
        br_is_SF_t_temp = np.array([])
        if self.len_br_is_SF_t > 0:
            br_is_SF_t_temp = self.br_is_SF_t[i_z_ss][i_br_ss]
        br_sfe_t_temp = np.array([])
        if self.len_br_sfe_t > 0:
            max_sfe = max(self.br_sfe_t[i_z_ss][i_br_ss])
            if max_sfe > 0.0:
                br_sfe_t_temp = [max_sfe]*self.len_br_sfe_t

        # Assigned pre-defined star formation history .. if provided
        br_sfh_temp = np.array([])
        if self.len_br_sfh > 0:
            br_sfh_temp = self.br_sfh[i_z_ss][i_br_ss]

        # Create an OMEGA+ instance (GAMMA branch)
        self.kwargs["is_SF_t"] = br_is_SF_t_temp
        self.kwargs["sfe_t"] = br_sfe_t_temp
        self.kwargs["sfh_with_sfe"] = br_sfh_temp
        self.kwargs["is_SF"] = br_is_SF_temp
        self.kwargs["t_merge"] = self.br_t_merge[i_z_ss][i_br_ss]
        return (i_br_ss, omega_plus.omega_plus(**self.kwargs))


